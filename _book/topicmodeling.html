<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Tidy Text Mining</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools">
  <meta name="generator" content="bookdown 0.0.74 and GitBook 2.6.7">

  <meta property="og:title" content="Tidy Text Mining" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools" />
  <meta name="github-repo" content="dgrtwo/tidy-text-mining" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tidy Text Mining" />
  
  <meta name="twitter:description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools" />
  

<meta name="author" content="Julia Silge and David Robinson">

<meta name="date" content="2016-07-07">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="tidying-and-casting-document-term-matrices.html">
<link rel="next" href="word2vec.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Tidy Text Mining</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-tidy-text"><i class="fa fa-check"></i><b>1.1</b> What is tidy text?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#outline"><i class="fa fa-check"></i><b>1.2</b> Outline</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tidytext.html"><a href="tidytext.html"><i class="fa fa-check"></i><b>2</b> The Tidy Text Format</a><ul>
<li class="chapter" data-level="2.1" data-path="tidytext.html"><a href="tidytext.html#the-unnest_tokens-function"><i class="fa fa-check"></i><b>2.1</b> The <code>unnest_tokens</code> function</a></li>
<li class="chapter" data-level="2.2" data-path="tidytext.html"><a href="tidytext.html#example-the-works-of-jane-austen"><i class="fa fa-check"></i><b>2.2</b> Example: the works of Jane Austen</a><ul>
<li class="chapter" data-level="2.2.1" data-path="tidytext.html"><a href="tidytext.html#the-gutenbergr-package"><i class="fa fa-check"></i><b>2.2.1</b> The gutenbergr package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sentiment.html"><a href="sentiment.html"><i class="fa fa-check"></i><b>3</b> Sentiment Analysis with Tidy Data</a><ul>
<li class="chapter" data-level="3.1" data-path="sentiment.html"><a href="sentiment.html#the-sentiments-dataset"><i class="fa fa-check"></i><b>3.1</b> The sentiments dataset</a></li>
<li class="chapter" data-level="3.2" data-path="sentiment.html"><a href="sentiment.html#sentiment-analysis-with-inner-join"><i class="fa fa-check"></i><b>3.2</b> Sentiment analysis with inner join</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sentiment.html"><a href="sentiment.html#most-common-positive-and-negative-words"><i class="fa fa-check"></i><b>3.2.1</b> Most common positive and negative words</a></li>
<li class="chapter" data-level="3.2.2" data-path="sentiment.html"><a href="sentiment.html#wordclouds"><i class="fa fa-check"></i><b>3.2.2</b> Wordclouds</a></li>
<li class="chapter" data-level="3.2.3" data-path="sentiment.html"><a href="sentiment.html#looking-at-units-beyond-just-words"><i class="fa fa-check"></i><b>3.2.3</b> Looking at units beyond just words</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tfidf.html"><a href="tfidf.html"><i class="fa fa-check"></i><b>4</b> TF-IDF: Analyzing word and document frequency</a><ul>
<li class="chapter" data-level="4.1" data-path="tfidf.html"><a href="tfidf.html#term-frequency-and-inverse-document-frequency"><i class="fa fa-check"></i><b>4.1</b> Term frequency and inverse document frequency</a></li>
<li class="chapter" data-level="4.2" data-path="tfidf.html"><a href="tfidf.html#the-bind_tf_idf-function"><i class="fa fa-check"></i><b>4.2</b> The bind_tf_idf function</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html"><i class="fa fa-check"></i><b>5</b> Tidying and casting document-term matrices</a><ul>
<li class="chapter" data-level="5.1" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html#tidying-a-document-term-matrix"><i class="fa fa-check"></i><b>5.1</b> Tidying a document-term matrix</a></li>
<li class="chapter" data-level="5.2" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html#casting-tidy-text-data-into-a-documenttermmatrix"><i class="fa fa-check"></i><b>5.2</b> Casting tidy text data into a DocumentTermMatrix</a></li>
<li class="chapter" data-level="5.3" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html#tidying-corpus-objects-with-metadata"><i class="fa fa-check"></i><b>5.3</b> Tidying corpus objects with metadata</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="topicmodeling.html"><a href="topicmodeling.html"><i class="fa fa-check"></i><b>6</b> Topic Modeling</a><ul>
<li class="chapter" data-level="6.1" data-path="topicmodeling.html"><a href="topicmodeling.html#can-we-tell-the-difference-between-dickens-wells-verne-and-austen"><i class="fa fa-check"></i><b>6.1</b> Can we tell the difference between Dickens, Wells, Verne, and Austen?</a></li>
<li class="chapter" data-level="6.2" data-path="topicmodeling.html"><a href="topicmodeling.html#setup"><i class="fa fa-check"></i><b>6.2</b> Setup</a></li>
<li class="chapter" data-level="6.3" data-path="topicmodeling.html"><a href="topicmodeling.html#latent-dirichlet-allocation-with-the-topicmodels-package"><i class="fa fa-check"></i><b>6.3</b> Latent Dirichlet Allocation with the topicmodels package</a></li>
<li class="chapter" data-level="6.4" data-path="topicmodeling.html"><a href="topicmodeling.html#per-document-classification"><i class="fa fa-check"></i><b>6.4</b> Per-document classification</a><ul>
<li class="chapter" data-level="6.4.1" data-path="topicmodeling.html"><a href="topicmodeling.html#by-word-assignments-augment"><i class="fa fa-check"></i><b>6.4.1</b> By word assignments: <code>augment</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="word2vec.html"><a href="word2vec.html"><i class="fa fa-check"></i><b>7</b> Tidying word2vec Models from the glove Package</a></li>
<li class="chapter" data-level="8" data-path="yelp.html"><a href="yelp.html"><i class="fa fa-check"></i><b>8</b> Predicting ratings from text in the Yelp food reviews dataset</a><ul>
<li class="chapter" data-level="8.1" data-path="yelp.html"><a href="yelp.html#setup-1"><i class="fa fa-check"></i><b>8.1</b> Setup</a></li>
<li class="chapter" data-level="8.2" data-path="yelp.html"><a href="yelp.html#tidy-sentiment-analysis"><i class="fa fa-check"></i><b>8.2</b> Tidy sentiment analysis</a></li>
<li class="chapter" data-level="8.3" data-path="yelp.html"><a href="yelp.html#which-words-are-positive-or-negative"><i class="fa fa-check"></i><b>8.3</b> Which words are positive or negative?</a></li>
<li class="chapter" data-level="8.4" data-path="yelp.html"><a href="yelp.html#comparing-to-sentiment-analysis"><i class="fa fa-check"></i><b>8.4</b> Comparing to sentiment analysis</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="placeholder.html"><a href="placeholder.html"><i class="fa fa-check"></i><b>9</b> Some analysis goes here</a></li>
<li class="chapter" data-level="10" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>10</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Tidy Text Mining</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="topicmodeling" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Topic Modeling</h1>
<p>Topic modeling is a method for unsupervised classification of documents, by modeling each document as a mixture of topics and each topic as a mixture of words. <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet allocation</a> is a particularly popular method for fitting a topic model.</p>
<p>We can use tidy text principles, as described in <a href="tidytext.html">the main vignette</a>, to approach topic modeling using consistent and effective tools. In particular, we’ll be using tidying functions for LDA objects from the <a href="https://cran.r-project.org/package=topicmodels">topicmodels package</a>.</p>
<div id="can-we-tell-the-difference-between-dickens-wells-verne-and-austen" class="section level2">
<h2><span class="header-section-number">6.1</span> Can we tell the difference between Dickens, Wells, Verne, and Austen?</h2>
<p>Suppose a vandal has broken into your study and torn apart four of your books:</p>
<ul>
<li><em>Great Expectations</em> by Charles Dickens</li>
<li><em>The War of the Worlds</em> by H.G. Wells</li>
<li><em>Twenty Thousand Leagues Under the Sea</em> by Jules Verne</li>
<li><em>Pride and Prejudice</em> by Jane Austen</li>
</ul>
<p>This vandal has torn the books into individual chapters, and left them in one large pile. How can we restore these disorganized chapters to their original books?</p>
</div>
<div id="setup" class="section level2">
<h2><span class="header-section-number">6.2</span> Setup</h2>
<p>We’ll retrieve four books using the gutenbergr package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(gutenbergr)

titles &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Twenty Thousand Leagues under the Sea&quot;</span>, <span class="st">&quot;The War of the Worlds&quot;</span>,
            <span class="st">&quot;Pride and Prejudice&quot;</span>, <span class="st">&quot;Great Expectations&quot;</span>)

books &lt;-<span class="st"> </span><span class="kw">gutenberg_works</span>(title %in%<span class="st"> </span>titles) %&gt;%
<span class="st">  </span><span class="kw">gutenberg_download</span>(<span class="dt">meta_fields =</span> <span class="st">&quot;title&quot;</span>)

books</code></pre></div>
<pre><code>## # A tibble: 51,663 x 3
##    gutenberg_id                                                        text                 title
##           &lt;int&gt;                                                       &lt;chr&gt;                 &lt;chr&gt;
## 1            36                                       The War of the Worlds The War of the Worlds
## 2            36                                                             The War of the Worlds
## 3            36                                       by H. G. Wells [1898] The War of the Worlds
## 4            36                                                             The War of the Worlds
## 5            36                                                             The War of the Worlds
## 6            36              But who shall dwell in these worlds if they be The War of the Worlds
## 7            36             inhabited? .  .  .  Are we or they Lords of the The War of the Worlds
## 8            36      World? .  .  .  And how are all things made for man?-- The War of the Worlds
## 9            36                KEPLER (quoted in The Anatomy of Melancholy) The War of the Worlds
## 10           36                                                             The War of the Worlds
## # ... with 51,653 more rows</code></pre>
<p>As pre-processing, we divide these into chapters, use tidytext’s <code>unnest_tokens</code> to separate them into words, then remove <code>stop_words</code>. We’re treating every chapter as a separate “document”, each with a name like <code>Great Expectations_1</code> or <code>Pride and Prejudice_11</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidytext)
<span class="kw">library</span>(stringr)
<span class="kw">library</span>(tidyr)

by_chapter &lt;-<span class="st"> </span>books %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(title) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">chapter =</span> <span class="kw">cumsum</span>(<span class="kw">str_detect</span>(text, <span class="kw">regex</span>(<span class="st">&quot;^chapter &quot;</span>, <span class="dt">ignore_case =</span> <span class="ot">TRUE</span>)))) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">filter</span>(chapter &gt;<span class="st"> </span><span class="dv">0</span>)

by_chapter_word &lt;-<span class="st"> </span>by_chapter %&gt;%
<span class="st">  </span><span class="kw">unite</span>(title_chapter, title, chapter) %&gt;%
<span class="st">  </span><span class="kw">unnest_tokens</span>(word, text)

word_counts &lt;-<span class="st"> </span>by_chapter_word %&gt;%
<span class="st">  </span><span class="kw">anti_join</span>(stop_words) %&gt;%
<span class="st">  </span><span class="kw">count</span>(title_chapter, word, <span class="dt">sort =</span> <span class="ot">TRUE</span>) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>()

word_counts</code></pre></div>
<pre><code>## # A tibble: 104,721 x 3
##               title_chapter    word     n
##                       &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
## 1     Great Expectations_57     joe    88
## 2      Great Expectations_7     joe    70
## 3     Great Expectations_17   biddy    63
## 4     Great Expectations_27     joe    58
## 5     Great Expectations_38 estella    58
## 6      Great Expectations_2     joe    56
## 7     Great Expectations_23  pocket    53
## 8     Great Expectations_15     joe    50
## 9     Great Expectations_18     joe    50
## 10 The War of the Worlds_16 brother    50
## # ... with 104,711 more rows</code></pre>
</div>
<div id="latent-dirichlet-allocation-with-the-topicmodels-package" class="section level2">
<h2><span class="header-section-number">6.3</span> Latent Dirichlet Allocation with the topicmodels package</h2>
<p>Right now this data frame is in a tidy form, with one-term-per-document-per-row. However, the topicmodels package requires a <code>DocumentTermMatrix</code> (from the tm package). As described in <a href="tidying_casting.html">this vignette</a>, we can cast a one-token-per-row table into a <code>DocumentTermMatrix</code> with tidytext’s <code>cast_dtm</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chapters_dtm &lt;-<span class="st"> </span>word_counts %&gt;%
<span class="st">  </span><span class="kw">cast_dtm</span>(title_chapter, word, n)

chapters_dtm</code></pre></div>
<pre><code>## &lt;&lt;DocumentTermMatrix (documents: 193, terms: 18215)&gt;&gt;
## Non-/sparse entries: 104721/3410774
## Sparsity           : 97%
## Maximal term length: 19
## Weighting          : term frequency (tf)</code></pre>
<p>Now we are ready to use the <a href="https://cran.r-project.org/package=topicmodels">topicmodels</a> package to create a four topic LDA model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(topicmodels)
chapters_lda &lt;-<span class="st"> </span><span class="kw">LDA</span>(chapters_dtm, <span class="dt">k =</span> <span class="dv">4</span>, <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">seed =</span> <span class="dv">1234</span>))
chapters_lda</code></pre></div>
<pre><code>## A LDA_VEM topic model with 4 topics.</code></pre>
<p>(In this case we know there are four topics because there are four books; in practice we may need to try a few different values of <code>k</code>).</p>
<p>Now tidytext gives us the option of <em>returning</em> to a tidy analysis, using the <code>tidy</code> and <code>augment</code> verbs borrowed from the <a href="https://github.com/dgrtwo/broom">broom package</a>. In particular, we start with the <code>tidy</code> verb.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chapters_lda_td &lt;-<span class="st"> </span><span class="kw">tidy</span>(chapters_lda)
chapters_lda_td</code></pre></div>
<pre><code>## # A tibble: 72,860 x 3
##    topic    term         beta
##    &lt;int&gt;   &lt;chr&gt;        &lt;dbl&gt;
## 1      1     joe 5.830326e-17
## 2      2     joe 3.194447e-57
## 3      3     joe 4.162676e-24
## 4      4     joe 1.445030e-02
## 5      1   biddy 7.846976e-27
## 6      2   biddy 4.672244e-69
## 7      3   biddy 2.259711e-46
## 8      4   biddy 4.767972e-03
## 9      1 estella 3.827272e-06
## 10     2 estella 5.316964e-65
## # ... with 72,850 more rows</code></pre>
<p>Notice that this has turned the model into a one-topic-per-term-per-row format. For each combination the model has <span class="math inline">\(\beta\)</span>, the probability of that term being generated from that topic.</p>
<p>We could use dplyr’s <code>top_n</code> to find the top 5 terms within each topic:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">top_terms &lt;-<span class="st"> </span>chapters_lda_td %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(topic) %&gt;%
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">5</span>, beta) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(topic, -beta)

top_terms</code></pre></div>
<pre><code>## # A tibble: 20 x 3
##    topic      term        beta
##    &lt;int&gt;     &lt;chr&gt;       &lt;dbl&gt;
## 1      1 elizabeth 0.014107538
## 2      1     darcy 0.008814258
## 3      1      miss 0.008706741
## 4      1    bennet 0.006947431
## 5      1      jane 0.006497512
## 6      2   captain 0.015507696
## 7      2  nautilus 0.013050048
## 8      2       sea 0.008850073
## 9      2      nemo 0.008708397
## 10     2       ned 0.008030799
## 11     3    people 0.006797400
## 12     3  martians 0.006512569
## 13     3      time 0.005347115
## 14     3     black 0.005278302
## 15     3     night 0.004483143
## 16     4       joe 0.014450300
## 17     4      time 0.006847574
## 18     4       pip 0.006817363
## 19     4    looked 0.006365257
## 20     4      miss 0.006228387</code></pre>
<p>This model lends itself to a visualization:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())

top_terms %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">reorder</span>(term, beta)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(term, beta)) +
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>) +
<span class="st">  </span><span class="kw">facet_wrap</span>(~<span class="st"> </span>topic, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">15</span>, <span class="dt">angle =</span> <span class="dv">90</span>, <span class="dt">hjust =</span> <span class="dv">1</span>))</code></pre></div>
<p><img src="tidy-text-mining_files/figure-html/top_terms_plot-1.png" width="672" /></p>
<p>These topics are pretty clearly associated with the four books! There’s no question that the topic of “nemo”, “sea”, and “nautilus” belongs to <em>Twenty Thousand Leagues Under the Sea</em>, and that “jane”, “darcy”, and “elizabeth” belongs to <em>Pride and Prejudice</em>. We see “pip” and “joe” from <em>Great Expectations</em> and “martians”, “black”, and “night” from <em>The War of the Worlds</em>.</p>
</div>
<div id="per-document-classification" class="section level2">
<h2><span class="header-section-number">6.4</span> Per-document classification</h2>
<p>Each chapter was a “document” in this analysis. Thus, we may want to know which topics are associated with each document. Can we put the chapters back together in the correct books?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chapters_lda_gamma &lt;-<span class="st"> </span><span class="kw">tidy</span>(chapters_lda, <span class="dt">matrix =</span> <span class="st">&quot;gamma&quot;</span>)
chapters_lda_gamma</code></pre></div>
<pre><code>## # A tibble: 772 x 3
##                    document topic        gamma
##                       &lt;chr&gt; &lt;int&gt;        &lt;dbl&gt;
## 1     Great Expectations_57     1 1.351886e-05
## 2      Great Expectations_7     1 1.470726e-05
## 3     Great Expectations_17     1 2.117127e-05
## 4     Great Expectations_27     1 1.919746e-05
## 5     Great Expectations_38     1 3.544403e-01
## 6      Great Expectations_2     1 1.723723e-05
## 7     Great Expectations_23     1 5.507241e-01
## 8     Great Expectations_15     1 1.682503e-02
## 9     Great Expectations_18     1 1.272044e-05
## 10 The War of the Worlds_16     1 1.084337e-05
## # ... with 762 more rows</code></pre>
<p>Setting <code>matrix = &quot;gamma&quot;</code> returns a tidied version with one-document-per-topic-per-row. Now that we have these document classifiations, we can see how well our unsupervised learning did at distinguishing the four books. First we re-separate the document name into title and chapter:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chapters_lda_gamma &lt;-<span class="st"> </span>chapters_lda_gamma %&gt;%
<span class="st">  </span><span class="kw">separate</span>(document, <span class="kw">c</span>(<span class="st">&quot;title&quot;</span>, <span class="st">&quot;chapter&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot;_&quot;</span>, <span class="dt">convert =</span> <span class="ot">TRUE</span>)
chapters_lda_gamma</code></pre></div>
<pre><code>## # A tibble: 772 x 4
##                    title chapter topic        gamma
## *                  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;        &lt;dbl&gt;
## 1     Great Expectations      57     1 1.351886e-05
## 2     Great Expectations       7     1 1.470726e-05
## 3     Great Expectations      17     1 2.117127e-05
## 4     Great Expectations      27     1 1.919746e-05
## 5     Great Expectations      38     1 3.544403e-01
## 6     Great Expectations       2     1 1.723723e-05
## 7     Great Expectations      23     1 5.507241e-01
## 8     Great Expectations      15     1 1.682503e-02
## 9     Great Expectations      18     1 1.272044e-05
## 10 The War of the Worlds      16     1 1.084337e-05
## # ... with 762 more rows</code></pre>
<p>Then we examine what fraction of chapters we got right for each:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(chapters_lda_gamma, <span class="kw">aes</span>(gamma, <span class="dt">fill =</span> <span class="kw">factor</span>(topic))) +
<span class="st">  </span><span class="kw">geom_histogram</span>() +
<span class="st">  </span><span class="kw">facet_wrap</span>(~<span class="st"> </span>title, <span class="dt">nrow =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="tidy-text-mining_files/figure-html/chapters_lda_gamma_plot-1.png" width="672" /></p>
<p>We notice that almost all of the chapters from <em>Pride and Prejudice</em>, <em>War of the Worlds</em>, and <em>Twenty Thousand Leagues Under the Sea</em> were uniquely identified as a single topic each.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chapter_classifications &lt;-<span class="st"> </span>chapters_lda_gamma %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(title, chapter) %&gt;%
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">1</span>, gamma) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(gamma)

chapter_classifications</code></pre></div>
<pre><code>## # A tibble: 193 x 4
##                 title chapter topic     gamma
##                 &lt;chr&gt;   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;
## 1  Great Expectations      54     3 0.4803234
## 2  Great Expectations      22     4 0.5356506
## 3  Great Expectations      31     4 0.5464851
## 4  Great Expectations      23     1 0.5507241
## 5  Great Expectations      33     4 0.5700737
## 6  Great Expectations      47     4 0.5802089
## 7  Great Expectations      56     4 0.5984806
## 8  Great Expectations      38     4 0.6455341
## 9  Great Expectations      11     4 0.6689600
## 10 Great Expectations      44     4 0.6777974
## # ... with 183 more rows</code></pre>
<p>We can determine this by finding the consensus book for each, which we note is correct based on our earlier visualization:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">book_topics &lt;-<span class="st"> </span>chapter_classifications %&gt;%
<span class="st">  </span><span class="kw">count</span>(title, topic) %&gt;%
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">1</span>, n) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">consensus =</span> title, topic)

book_topics</code></pre></div>
<pre><code>## # A tibble: 4 x 2
##                               consensus topic
##                                   &lt;chr&gt; &lt;int&gt;
## 1                    Great Expectations     4
## 2                   Pride and Prejudice     1
## 3                 The War of the Worlds     3
## 4 Twenty Thousand Leagues under the Sea     2</code></pre>
<p>Then we see which chapters were misidentified:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chapter_classifications %&gt;%
<span class="st">  </span><span class="kw">inner_join</span>(book_topics, <span class="dt">by =</span> <span class="st">&quot;topic&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">count</span>(title, consensus)</code></pre></div>
<pre><code>## Source: local data frame [6 x 3]
## Groups: title [?]
## 
##                                   title                             consensus     n
##                                   &lt;chr&gt;                                 &lt;chr&gt; &lt;int&gt;
## 1                    Great Expectations                    Great Expectations    57
## 2                    Great Expectations                   Pride and Prejudice     1
## 3                    Great Expectations                 The War of the Worlds     1
## 4                   Pride and Prejudice                   Pride and Prejudice    61
## 5                 The War of the Worlds                 The War of the Worlds    27
## 6 Twenty Thousand Leagues under the Sea Twenty Thousand Leagues under the Sea    46</code></pre>
<p>We see that only a few chapters from <em>Great Expectations</em> were misclassified. Not bad for unsupervised clustering!</p>
<div id="by-word-assignments-augment" class="section level3">
<h3><span class="header-section-number">6.4.1</span> By word assignments: <code>augment</code></h3>
<p>One important step in the topic modeling expectation-maximization algorithm is assigning each word in each document to a topic. The more words in a document are assigned to that topic, generally, the more weight (<code>gamma</code>) will go on that document-topic classification.</p>
<p>We may want to take the original document-word pairs and find which words in each document were assigned to which topic. This is the job of the <code>augment</code> verb.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">assignments &lt;-<span class="st"> </span><span class="kw">augment</span>(chapters_lda, <span class="dt">data =</span> chapters_dtm)</code></pre></div>
<p>We can combine this with the consensus book titles to find which words were incorrectly classified.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">assignments &lt;-<span class="st"> </span>assignments %&gt;%
<span class="st">  </span><span class="kw">separate</span>(document, <span class="kw">c</span>(<span class="st">&quot;title&quot;</span>, <span class="st">&quot;chapter&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot;_&quot;</span>, <span class="dt">convert =</span> <span class="ot">TRUE</span>) %&gt;%
<span class="st">  </span><span class="kw">inner_join</span>(book_topics, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;.topic&quot;</span> =<span class="st"> &quot;topic&quot;</span>))

assignments</code></pre></div>
<pre><code>## # A tibble: 104,721 x 6
##                 title chapter  term count .topic          consensus
##                 &lt;chr&gt;   &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;              &lt;chr&gt;
## 1  Great Expectations      57   joe    88      4 Great Expectations
## 2  Great Expectations       7   joe    70      4 Great Expectations
## 3  Great Expectations      17   joe     5      4 Great Expectations
## 4  Great Expectations      27   joe    58      4 Great Expectations
## 5  Great Expectations       2   joe    56      4 Great Expectations
## 6  Great Expectations      23   joe     1      4 Great Expectations
## 7  Great Expectations      15   joe    50      4 Great Expectations
## 8  Great Expectations      18   joe    50      4 Great Expectations
## 9  Great Expectations       9   joe    44      4 Great Expectations
## 10 Great Expectations      13   joe    40      4 Great Expectations
## # ... with 104,711 more rows</code></pre>
<p>We can, for example, create a “confusion matrix” using dplyr’s <code>count</code> and tidyr’s <code>spread</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">assignments %&gt;%
<span class="st">  </span><span class="kw">count</span>(title, consensus, <span class="dt">wt =</span> count) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(consensus, n, <span class="dt">fill =</span> <span class="dv">0</span>)</code></pre></div>
<pre><code>## Source: local data frame [4 x 5]
## Groups: title [4]
## 
##                                   title Great Expectations Pride and Prejudice
## *                                 &lt;chr&gt;              &lt;dbl&gt;               &lt;dbl&gt;
## 1                    Great Expectations              49770                3876
## 2                   Pride and Prejudice                  1               37229
## 3                 The War of the Worlds                  0                   0
## 4 Twenty Thousand Leagues under the Sea                  0                   5
##   The War of the Worlds Twenty Thousand Leagues under the Sea
## *                 &lt;dbl&gt;                                 &lt;dbl&gt;
## 1                  1845                                    77
## 2                     7                                     5
## 3                 22561                                     7
## 4                     0                                 39629</code></pre>
<p>We notice that almost all the words for <em>Pride and Prejudice</em>, <em>Twenty Thousand Leagues Under the Sea</em>, and <em>War of the Worlds</em> were correctly assigned, while <em>Great Expectations</em> had a fair amount of misassignment.</p>
<p>What were the most commonly mistaken words?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wrong_words &lt;-<span class="st"> </span>assignments %&gt;%
<span class="st">  </span><span class="kw">filter</span>(title !=<span class="st"> </span>consensus)

wrong_words</code></pre></div>
<pre><code>## # A tibble: 4,535 x 6
##                                    title chapter     term count .topic
##                                    &lt;chr&gt;   &lt;int&gt;    &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1                     Great Expectations      38  brother     2      1
## 2                     Great Expectations      22  brother     4      1
## 3                     Great Expectations      23     miss     2      1
## 4                     Great Expectations      22     miss    23      1
## 5  Twenty Thousand Leagues under the Sea       8     miss     1      1
## 6                     Great Expectations      31     miss     1      1
## 7                     Great Expectations       5 sergeant    37      1
## 8                     Great Expectations      46  captain     1      2
## 9                     Great Expectations      32  captain     1      2
## 10                 The War of the Worlds      17  captain     5      2
##                                consensus
##                                    &lt;chr&gt;
## 1                    Pride and Prejudice
## 2                    Pride and Prejudice
## 3                    Pride and Prejudice
## 4                    Pride and Prejudice
## 5                    Pride and Prejudice
## 6                    Pride and Prejudice
## 7                    Pride and Prejudice
## 8  Twenty Thousand Leagues under the Sea
## 9  Twenty Thousand Leagues under the Sea
## 10 Twenty Thousand Leagues under the Sea
## # ... with 4,525 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">wrong_words %&gt;%
<span class="st">  </span><span class="kw">count</span>(title, consensus, term, <span class="dt">wt =</span> count) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</code></pre></div>
<pre><code>## # A tibble: 3,500 x 4
##                 title             consensus     term     n
##                 &lt;chr&gt;                 &lt;chr&gt;    &lt;chr&gt; &lt;dbl&gt;
## 1  Great Expectations   Pride and Prejudice     love    44
## 2  Great Expectations   Pride and Prejudice sergeant    37
## 3  Great Expectations   Pride and Prejudice     lady    32
## 4  Great Expectations   Pride and Prejudice     miss    26
## 5  Great Expectations The War of the Worlds     boat    25
## 6  Great Expectations   Pride and Prejudice   father    19
## 7  Great Expectations The War of the Worlds    water    19
## 8  Great Expectations   Pride and Prejudice     baby    18
## 9  Great Expectations   Pride and Prejudice  flopson    18
## 10 Great Expectations   Pride and Prejudice   family    16
## # ... with 3,490 more rows</code></pre>
<p>Notice the word “flopson” here; these wrong words do not necessarily appear in the novels they were misassigned to. Indeed, we can confirm “flopson” appears only in <em>Great Expectations</em>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">word_counts %&gt;%
<span class="st">  </span><span class="kw">filter</span>(word ==<span class="st"> &quot;flopson&quot;</span>)</code></pre></div>
<pre><code>## # A tibble: 3 x 3
##           title_chapter    word     n
##                   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
## 1 Great Expectations_22 flopson    10
## 2 Great Expectations_23 flopson     7
## 3 Great Expectations_33 flopson     1</code></pre>
<p>The algorithm is stochastic and iterative, and it can accidentally land on a topic that spans multiple books.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tidying-and-casting-document-term-matrices.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="word2vec.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dgrtwo/tidy-text-mining/edit/master/06-topic-models.Rmd",
"text": null
},
"download": ["tidy-text-mining.pdf", "tidy-text-mining.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
